{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Neural Network with Pytorch Geometric\n",
    "\n",
    "In the last decade, Deep Learning approaches (e.g. Convolutional Neural Networks and Recurrent Neural Networks) allowed to achieve unprecedented performance on a broad range of problems coming from a variety of different fields (e.g. Computer Vision and Speech Recognition). Despite the results obtained, research on DL techniques has mainly focused so far on data defined on Euclidean domains (i.e. grids). Nonetheless, in a multitude of different fields, such as: Biology, Physics, Network Science, Recommender Systems and Computer Graphics; one may have to deal with data defined on non-Euclidean domains (i.e. graphs and manifolds). The adoption of Deep Learning in these particular fields has been lagging behind until very recently, primarily since the non-Euclidean nature of data makes the definition of basic operations (such as convolution) rather elusive. Geometric Deep Learning deals in this sense with the extension of Deep Learning techniques to graph/manifold structured data.\n",
    "\n",
    "## Resources\n",
    "- https://arxiv.org/pdf/1706.02216.pdf\n",
    "- https://github.com/rusty1s/pytorch_geometric\n",
    "- https://towardsdatascience.com/hands-on-graph-neural-networks-with-pytorch-pytorch-geometric-359487e221a8\n",
    "- https://towardsdatascience.com/a-gentle-introduction-to-graph-neural-network-basics-deepwalk-and-graphsage-db5d540d50b3\n",
    "- http://geometricdeeplearning.com/\n",
    "- https://pytorch-geometric.readthedocs.io/en/latest/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph\n",
    "In Computer Science, a graph is a data structure consisting of two components, verticies and edges. A graph $G$ can be well described by the set of vertices $V$ and edges $E$ it contains.\n",
    "$$ G = (V,E) $$\n",
    "\n",
    "Edges can be directed or undirected. Vertices are usually called Nodes.\n",
    "![directed graph](http://think-like-a-git.net/assets/images2/directed-graph.png) ![undirected](http://think-like-a-git.net/assets/images2/undirected-graph.png)\n",
    "\n",
    "## Graph Neural Network\n",
    "Works on Graph Structure, each node in the graph is associated with a label and we would like to predict these labels  of the nodes. The concept is presented in the [first Graph Paper](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.1015.7227&rep=rep1&type=pdf) where it was first introduced.\n",
    "In the node classification problem setup, each node $\\nu$ is characterised by its feature $x_\\nu$ and associated ground truth label $t_\\nu$. If we have a prtially labeled graph, we would like to use the labeled nodes to predicte the labels for the unlabeled nodes. \n",
    "\n",
    "For partially labeled graph $G$, the goal is to use the labeled nodes to predict the unlabeled ones. It learns to represent each node with a $d$ dimensional vector (state) $h_\\nu$ with contains the information of its neighborhood. \n",
    "$$\\mathbf{h}_\\nu = f(\\mathbf{X}_\\nu, \\mathbf{X}_{co[\\nu]}, \\mathbf{h}_{ne[\\nu]}, \\mathbf{X}_{ne[\\nu]})$$\n",
    "$$\\mathbf{O}_\\nu = \\mathcal{g}(\\mathbf{h}_\\nu, \\mathbf{x}_\\nu)$$\n",
    "\n",
    "where $x_\\nu$, $x_{co[\\nu]}$,  $h_{ne[\\nu]}$, $x_{ne[\\nu]}$ are the features of $\\nu$, the features of its edges, the states, and the features of the nodes in the neighbourhood of $\\nu$, respectively. Since we are seeking a solution for $h_\\nu$, using [Banach fixed point theorm](https://en.wikipedia.org/wiki/Fixed-point_theorem), namely $\\exists$ solution which $x=f(x)$.\n",
    "\n",
    "Rewriting the above  equation as an iterative update process, which is called __message passing__ or __neighbourhood aggregation__:\n",
    "$$ \\mathbf{H}^{t+1} = F(\\mathbf{H}^t, \\mathbf{X})$$\n",
    "\n",
    "Where $\\mathbf{H}$ and $\\mathbf{X}$ denote the concatenation of all $h$ and $x$. $\\mathbf{H}^t$ denotes the $t$-th iteration of $\\mathbf{H}$. \n",
    "\n",
    "$\\mathcal{f}$ and $\\mathcal{g}$ can be interpreted as the feedfoward neural networks. Assuming for each node $\\nu$ there is target $t_\\nu$ the loss can be written as follow:\n",
    "$$\\text{loss} = \\sum_{i=1}^p(\\mathbf{t}_i-\\mathbf{o}_i)$$\n",
    "where $p$ is the number of supervised nodes (see [Graph Neural Networks](https://arxiv.org/pdf/1812.08434.pdf) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GraphSAGE (Graph SAmple and aggreGatE)\n",
    "![graph](images/graphsage-d.png)\n",
    "\n",
    "Unlike embedding approaches that are based on matrix factorization, we leverage node features (e.g., text attributes, node profile information, node degrees) in order to learn an embedding function that generalizes to unseen nodes. By incorporating node features in the learning algorithm, we simultaneously learn the topological structure of each node’s neighborhood as well as the distribution of node features in the neighborhood.  While we focus on feature-rich graphs (e.g., citation data with text attributes, biological data with functional/molecular markers), our approach can also make use of structural features that are present in all graphs (e.g., node degrees).\n",
    "\n",
    "To learn embedding for each node in an inductive way: [Inductive Representation Learning on Large Graphs](https://arxiv.org/pdf/1706.02216.pdf)\n",
    "![graphsage](images/graphsage.png) \n",
    "\n",
    "we represent each node as an aggregation of its neighbourhood. \n",
    "\n",
    "$$ \\mathbf{h}^k_{\\mathcal{N}(\\nu)} \\leftarrow \\text{AGGREGATE}_k ({\\mathbf{h}^{k-1}_u, \\forall u \\in \\mathcal{N}(\\nu)})$$\n",
    "\n",
    "$$ \\mathbf{h}^k_\\nu \\leftarrow \\sigma(\\mathbf{W}^k . \\text{CONCAT}(\\mathbf{h}^{k-1}_\\nu, \\mathbf{h}^k_{\\mathcal{N}(\\nu)}))  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Geometric \n",
    "\n",
    "Documentation at: [Pytorch Geometric](https://pytorch-geometric.readthedocs.io/en/latest/notes/introduction.html) is a fast GPU implementation of Geometric Network using PyTorch. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "edge_index = torch.tensor([[0, 1, 1, 2],\n",
    "                           [1, 0, 2, 1]], dtype=torch.long)\n",
    "x = torch.tensor([[-1], [0], [1]], dtype=torch.float)\n",
    "# connect node 0 => 1, 1 => 0, 1=> 2 and 2 => 1\n",
    "data = Data(x=x, edge_index=edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![t](https://pytorch-geometric.readthedocs.io/en/latest/_images/graph.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[3, 1], edge_index=[2, 4])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 dimentional label data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[2,1], [5,6], [3,7], [12,0]], dtype=torch.float)\n",
    "y = torch.tensor([0, 1, 0, 1], dtype=torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Example Graph](images/example_graph.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = torch.tensor([[2,1], [5,6], [3,7], [12,0]], dtype=torch.float)\n",
    "y = torch.tensor([0, 1, 0, 1], dtype=torch.float)\n",
    "\n",
    "edge_index = torch.tensor([[0, 2, 1, 0, 3],\n",
    "                           [3, 1, 0, 1, 2]], dtype=torch.long)\n",
    "#connect node 0 => 3, 2 => 1, 1 => 0, 0 => 1, 3 => 2\n",
    "\n",
    "\n",
    "data = Data(x=x, y=y, edge_index=edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[4, 2], edge_index=[2, 5], y=[4])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Real-World Example — RecSys Challenge 2015\n",
    "Example taken form: [hands on graph neural network](https://towardsdatascience.com/hands-on-graph-neural-networks-with-pytorch-pytorch-geometric-359487e221a8), you can download the data from [recSys Challenge](https://2015.recsyschallenge.com/challenge.html).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "#data is mixed, so use low_memory false to take more records to determine its type\n",
    "df = pd.read_csv('../input/yoochoose-clicks.dat', low_memory=False, parse_dates = [1])\n",
    "df.columns=['session_id', 'timestamp', 'item_id', 'category']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are few files, yoochoose-click file which made of session_d, timestamp and the item clicked and then its category and yoochoose-buys what bought at the end of each session.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>item_id</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2014-04-07 10:54:09.868000+00:00</td>\n",
       "      <td>214536500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2014-04-07 10:54:46.998000+00:00</td>\n",
       "      <td>214536506</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2014-04-07 10:57:00.306000+00:00</td>\n",
       "      <td>214577561</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2014-04-07 13:56:37.614000+00:00</td>\n",
       "      <td>214662742</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2014-04-07 13:57:19.373000+00:00</td>\n",
       "      <td>214662742</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   session_id                        timestamp    item_id category\n",
       "0           1 2014-04-07 10:54:09.868000+00:00  214536500        0\n",
       "1           1 2014-04-07 10:54:46.998000+00:00  214536506        0\n",
       "2           1 2014-04-07 10:57:00.306000+00:00  214577561        0\n",
       "3           2 2014-04-07 13:56:37.614000+00:00  214662742        0\n",
       "4           2 2014-04-07 13:57:19.373000+00:00  214662742        0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>item_id</th>\n",
       "      <th>price</th>\n",
       "      <th>quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>420374</td>\n",
       "      <td>2014-04-06 18:44:58.314000+00:00</td>\n",
       "      <td>214537888</td>\n",
       "      <td>12462</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>420374</td>\n",
       "      <td>2014-04-06 18:44:58.325000+00:00</td>\n",
       "      <td>214537850</td>\n",
       "      <td>10471</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>281626</td>\n",
       "      <td>2014-04-06 09:40:13.032000+00:00</td>\n",
       "      <td>214535653</td>\n",
       "      <td>1883</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>420368</td>\n",
       "      <td>2014-04-04 06:13:28.848000+00:00</td>\n",
       "      <td>214530572</td>\n",
       "      <td>6073</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>420368</td>\n",
       "      <td>2014-04-04 06:13:28.858000+00:00</td>\n",
       "      <td>214835025</td>\n",
       "      <td>2617</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   session_id                        timestamp    item_id  price  quantity\n",
       "0      420374 2014-04-06 18:44:58.314000+00:00  214537888  12462         1\n",
       "1      420374 2014-04-06 18:44:58.325000+00:00  214537850  10471         1\n",
       "2      281626 2014-04-06 09:40:13.032000+00:00  214535653   1883         1\n",
       "3      420368 2014-04-04 06:13:28.848000+00:00  214530572   6073         1\n",
       "4      420368 2014-04-04 06:13:28.858000+00:00  214835025   2617         1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buy_df = pd.read_csv('../input/yoochoose-buys.dat', header=None, parse_dates = [1])\n",
    "buy_df.columns=['session_id','timestamp','item_id','price','quantity']\n",
    "buy_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "session_id     509696\n",
       "timestamp     1136477\n",
       "item_id         19949\n",
       "price             735\n",
       "quantity           28\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buy_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "session_id     9249729\n",
       "timestamp     32937844\n",
       "item_id          52739\n",
       "category           339\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "session_id     4431931\n",
       "timestamp     24590088\n",
       "item_id          48255\n",
       "category           330\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['valid_session'] = df.session_id.map(df.groupby('session_id')['item_id'].size() > 2)\n",
    "df = df.loc[df.valid_session].drop('valid_session',axis=1)\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "session_id    1000000\n",
       "timestamp     5546275\n",
       "item_id         37353\n",
       "category          259\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #randomly sample a couple of them\n",
    "sampled_session_id = np.random.choice(df.session_id.unique(), 1000000, replace=False)\n",
    "df = df.loc[df.session_id.isin(sampled_session_id)]\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "session_id    0\n",
       "timestamp     0\n",
       "item_id       0\n",
       "category      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.548274"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average length of session \n",
    "df.groupby('session_id')['item_id'].size().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>item_id</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>2014-04-02 13:17:46.940000+00:00</td>\n",
       "      <td>21302</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>2014-04-02 13:26:02.515000+00:00</td>\n",
       "      <td>25022</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>2014-04-02 13:30:12.318000+00:00</td>\n",
       "      <td>29039</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>19</td>\n",
       "      <td>2014-04-01 20:52:12.357000+00:00</td>\n",
       "      <td>5749</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>19</td>\n",
       "      <td>2014-04-01 20:52:13.758000+00:00</td>\n",
       "      <td>5749</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    session_id                        timestamp  item_id category\n",
       "9            3 2014-04-02 13:17:46.940000+00:00    21302        0\n",
       "10           3 2014-04-02 13:26:02.515000+00:00    25022        0\n",
       "11           3 2014-04-02 13:30:12.318000+00:00    29039        0\n",
       "48          19 2014-04-01 20:52:12.357000+00:00     5749        0\n",
       "49          19 2014-04-01 20:52:13.758000+00:00     5749        0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "item_encoder = LabelEncoder()\n",
    "df['item_id'] = item_encoder.fit_transform(df.item_id)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>item_id</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>2014-04-02 13:17:46.940000+00:00</td>\n",
       "      <td>21302</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>2014-04-02 13:26:02.515000+00:00</td>\n",
       "      <td>25022</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>2014-04-02 13:30:12.318000+00:00</td>\n",
       "      <td>29039</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>19</td>\n",
       "      <td>2014-04-01 20:52:12.357000+00:00</td>\n",
       "      <td>5749</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>19</td>\n",
       "      <td>2014-04-01 20:52:13.758000+00:00</td>\n",
       "      <td>5749</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    session_id                        timestamp  item_id category  label\n",
       "9            3 2014-04-02 13:17:46.940000+00:00    21302        0  False\n",
       "10           3 2014-04-02 13:26:02.515000+00:00    25022        0  False\n",
       "11           3 2014-04-02 13:30:12.318000+00:00    29039        0  False\n",
       "48          19 2014-04-01 20:52:12.357000+00:00     5749        0  False\n",
       "49          19 2014-04-01 20:52:13.758000+00:00     5749        0  False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'] = df.session_id.isin(buy_df.session_id)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.085507"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates('session_id')['label'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import InMemoryDataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "class YooChooseBinaryDataset(InMemoryDataset):\n",
    "    def __init__(self, root, df, transform=None, pre_transform=None):\n",
    "        super(YooChooseBinaryDataset, self).__init__(root, transform, pre_transform)\n",
    "        self.df = df\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "        \n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return []\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['../input/yoochoose_click_binary_1M_sess.dataset']\n",
    "\n",
    "    def download(self):\n",
    "        pass\n",
    "    \n",
    "    def process(self):\n",
    "        \n",
    "        data_list = []\n",
    "\n",
    "        # process by session_id\n",
    "        grouped = self.df.groupby('session_id')\n",
    "        for session_id, group in tqdm(grouped):\n",
    "            # to create an order of event, sess_item_id will be ordered by the click.\n",
    "            sess_item_id = LabelEncoder().fit_transform(group.item_id)\n",
    "            group = group.reset_index(drop=True)\n",
    "            group['sess_item_id'] = sess_item_id\n",
    "            node_features = group.loc[group.session_id==session_id,['sess_item_id','item_id', 'timestamp']].sort_values('timestamp').item_id.drop_duplicates().values\n",
    "\n",
    "            node_features = torch.LongTensor(node_features).unsqueeze(1)\n",
    "            target_nodes = group.sess_item_id.values[1:]\n",
    "            source_nodes = group.sess_item_id.values[:-1]\n",
    "\n",
    "            edge_index = torch.tensor([source_nodes,\n",
    "                                   target_nodes], dtype=torch.long)\n",
    "            x = node_features\n",
    "\n",
    "            y = torch.FloatTensor([group.label.values[0]])\n",
    "\n",
    "            data = Data(x=x, edge_index=edge_index, y=y)\n",
    "            data_list.append(data)\n",
    "        \n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = YooChooseBinaryDataset(root='../', df=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[3, 1], edge_index=[2, 2], y=[1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800000, 100000, 100000)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.shuffle()\n",
    "train_dataset = dataset[:800000]\n",
    "val_dataset = dataset[800000:900000]\n",
    "test_dataset = dataset[900000:]\n",
    "len(train_dataset), len(val_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\workspace\\anaconda3\\lib\\site-packages\\torch_geometric\\deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "batch_size= 1024\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37353"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_items = df.item_id.max() +1 \n",
    "num_items "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 128\n",
    "import torch\n",
    "from torch.nn import Sequential as Seq, Linear, ReLU\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch_geometric.utils import remove_self_loops, add_self_loops\n",
    "\n",
    "from torch_geometric.nn import GraphConv, TopKPooling, GatedGraphConv\n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
    "import torch.nn.functional as F\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.conv1 = SAGEConv(embed_dim, 128)\n",
    "        self.pool1 = TopKPooling(128, ratio=0.8)\n",
    "        self.conv2 = SAGEConv(128, 128)\n",
    "        self.pool2 = TopKPooling(128, ratio=0.8)\n",
    "        self.conv3 = SAGEConv(128, 128)\n",
    "        self.pool3 = TopKPooling(128, ratio=0.8)\n",
    "        self.item_embedding = torch.nn.Embedding(num_embeddings=df.item_id.max() +1, embedding_dim=embed_dim)\n",
    "        self.lin1 = torch.nn.Linear(256, 128)\n",
    "        self.lin2 = torch.nn.Linear(128, 64)\n",
    "        self.lin3 = torch.nn.Linear(64, 1)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(128)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(64)\n",
    "        self.act1 = torch.nn.ReLU()\n",
    "        self.act2 = torch.nn.ReLU()        \n",
    "  \n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        x = self.item_embedding(x)\n",
    "        x = x.squeeze(1)        \n",
    "\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        #x, edge_index, edge_attr, batch, perm, score[perm]\n",
    "\n",
    "        x, edge_index, _, batch, _, _ = self.pool1(x, edge_index, None, batch)\n",
    "        x1 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
    "\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "     \n",
    "        x, edge_index, _, batch, _, _ = self.pool2(x, edge_index, None, batch)\n",
    "        x2 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
    "\n",
    "        x = F.relu(self.conv3(x, edge_index))\n",
    "\n",
    "        x, edge_index, _, batch, _, _ = self.pool3(x, edge_index, None, batch)\n",
    "        x3 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
    "\n",
    "        x = x1 + x2 + x3\n",
    "\n",
    "        x = self.lin1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.lin2(x)\n",
    "        x = self.act2(x)      \n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "\n",
    "        x = torch.sigmoid(self.lin3(x)).squeeze(1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "model = Net().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "crit = torch.nn.BCELoss() \n",
    "# Bincary Cross Entropy Loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    loss_all = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        label = data.y.to(device)\n",
    "        loss = crit(output, label)\n",
    "        loss.backward()\n",
    "        loss_all += data.num_graphs * loss.item()\n",
    "        optimizer.step()\n",
    "    return loss_all / len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "def evaluate(loader):\n",
    "    model.eval()\n",
    "\n",
    "    predictions = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "\n",
    "            data = data.to(device)\n",
    "            pred = model(data).detach().cpu().numpy()\n",
    "\n",
    "            label = data.y.detach().cpu().numpy()\n",
    "            predictions.append(pred)\n",
    "            labels.append(label)\n",
    "\n",
    "    predictions = np.hstack(predictions)\n",
    "    labels = np.hstack(labels)\n",
    "    \n",
    "    return roc_auc_score(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.27878, Train Auc: 0.78729, Val Auc: 0.74861, Test Auc: 0.74285\n",
      "Epoch: 001, Loss: 0.25288, Train Auc: 0.81834, Val Auc: 0.74752, Test Auc: 0.74284\n",
      "Epoch: 002, Loss: 0.23888, Train Auc: 0.83994, Val Auc: 0.73371, Test Auc: 0.73015\n",
      "Epoch: 003, Loss: 0.22283, Train Auc: 0.86637, Val Auc: 0.72615, Test Auc: 0.72222\n",
      "Epoch: 004, Loss: 0.20462, Train Auc: 0.88331, Val Auc: 0.71712, Test Auc: 0.71261\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):\n",
    "    loss = train()\n",
    "    train_acc = evaluate(train_loader)\n",
    "    val_acc = evaluate(val_loader)    \n",
    "    test_acc = evaluate(test_loader)\n",
    "    print('Epoch: {:03d}, Loss: {:.5f}, Train Auc: {:.5f}, Val Auc: {:.5f}, Test Auc: {:.5f}'.\n",
    "          format(epoch, loss, train_acc, val_acc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
